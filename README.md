# Desafio Netshoes

## ğŸ“Œ VisÃ£o Geral

Este projeto Ã© uma soluÃ§Ã£o para o **Desafio Netshoes**, utilizando **Apache Kafka** para processamento e distribuiÃ§Ã£o de eventos.  
A aplicaÃ§Ã£o recebe um payload via API, publica a mensagem em um tÃ³pico Kafka principal e, a partir disso, um **processor** consome e divide esse payload em mÃºltiplos tÃ³picos, que sÃ£o entÃ£o consumidos por diferentes consumidores (simulados por scripts *demo*).

A arquitetura foi pensada para ser **escalÃ¡vel, desacoplada e extensÃ­vel**, permitindo fÃ¡cil adaptaÃ§Ã£o para novos payloads ou novos tipos de eventos.

---

## ğŸ—ï¸ Arquitetura

- **API**: ResponsÃ¡vel por receber o payload via HTTP e produzir a mensagem no Kafka.
- **Processor**: Consome o tÃ³pico principal, processa o payload e o divide em mÃºltiplos tÃ³picos.
- **Kafka + Zookeeper**: ResponsÃ¡veis pela mensageria e orquestraÃ§Ã£o dos eventos.
- **Consumers Demo**: Simulam consumidores finais para cada tÃ³pico gerado.
- **Shared**: CÃ³digo compartilhado entre API e Processor (schemas, producers, consumers e configuraÃ§Ãµes).

Cada aplicaÃ§Ã£o roda em seu **prÃ³prio container Docker**, seguindo boas prÃ¡ticas de arquitetura orientada a eventos.

---

## ğŸ“ Estrutura do Projeto

```

desafio_nets
â”œâ”€â”€ create_env.bat           # Script para criaÃ§Ã£o do ambiente virtual Python
â”œâ”€â”€ run_demo.bat             # Script para subir o projeto e executar os consumidores demo
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ docker-compose.yml   # ConfiguraÃ§Ã£o dos containers (Kafka, Zookeeper, API e Processor)
â”‚   â”œâ”€â”€ requirements.txt     # DependÃªncias do projeto
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ Dockerfile       # Dockerfile da API
â”‚   â”‚   â””â”€â”€ main.py          # ImplementaÃ§Ã£o da API
â”‚   â”œâ”€â”€ demo/
â”‚   â”‚   â”œâ”€â”€ itemConsumerDemo.py
â”‚   â”‚   â”œâ”€â”€ orderConsumerDemo.py
â”‚   â”‚   â”œâ”€â”€ orderProducerDemo.py
â”‚   â”‚   â””â”€â”€ paymentInfoConsumerDemo.py
â”‚   â”œâ”€â”€ processor/
â”‚   â”‚   â”œâ”€â”€ Dockerfile       # Dockerfile do Processor
â”‚   â”‚   â””â”€â”€ main.py          # ImplementaÃ§Ã£o do Processor
â”‚   â””â”€â”€ shared/
â”‚       â”œâ”€â”€ config/          # ConfiguraÃ§Ãµes do Kafka
â”‚       â”œâ”€â”€ consumers/       # Consumers base
â”‚       â”œâ”€â”€ data/            # Payloads de exemplo fornecidos no desafio
â”‚       â”œâ”€â”€ producers/       # Producers base
â”‚       â””â”€â”€ schemas/         # Schemas dos tÃ³picos Kafka
â””â”€â”€ tests/
â”œâ”€â”€ test_base_consumer.py
â”œâ”€â”€ test_base_processor.py
â””â”€â”€ test_base_producer.py

````

---

## â–¶ï¸ Como Rodar o Projeto

### PrÃ©-requisitos

Antes de iniciar, certifique-se de que possui:

1. **Python 3.10 ou superior**
2. **Docker** e **Docker Compose** instalados e em execuÃ§Ã£o
3. Sistema operacional **Windows** (scripts `.bat`)

---

### ExecuÃ§Ã£o

Para rodar o projeto, execute o seguinte arquivo na raiz do repositÃ³rio:

```bash
run_demo.bat
````

Este script irÃ¡:

* Criar o ambiente virtual Python
* Instalar as dependÃªncias
* Subir os containers Docker (Zookeeper, Kafka, API e Processor)
* Executar os consumidores *demo* para simulaÃ§Ã£o do processamento

---

## ğŸ”„ Fluxo de ExecuÃ§Ã£o

1. O usuÃ¡rio envia um payload JSON para a API.
2. A API publica a mensagem no tÃ³pico Kafka **`main`**.
3. O Processor consome o tÃ³pico **`main`**.
4. O Processor divide o payload com base nos **schemas** definidos.
5. Cada parte do payload Ã© publicada em seu respectivo tÃ³pico.
6. Os consumidores *demo* consomem esses tÃ³picos e exibem os dados processados.

> âš ï¸ A API retorna apenas a confirmaÃ§Ã£o de produÃ§Ã£o da mensagem no Kafka.
> NÃ£o hÃ¡ retorno do processamento dos consumidores.

---

## ğŸŒ Endpoints da API

### Enviar evento para processamento

```
POST http://localhost:8000/events/main
```

* **Body**: JSON
* **Content-Type**: `application/json`
* Produz a mensagem no tÃ³pico `main`

---

### Health Check

```
GET http://localhost:8000/health
```

* Retorno: `200 OK`
* Usado para verificaÃ§Ã£o de disponibilidade da API

---

## ğŸ§ª Testes

O projeto possui testes unitÃ¡rios para as principais entidades:

* Producers
* Consumers
* Processor

Os testes foram implementados utilizando **pytest**.

### Executando os testes

A partir do diretÃ³rio `app`, execute:

```bash
pytest -v
```

---

## ğŸš€ ConsideraÃ§Ãµes Finais

* Arquitetura orientada a eventos com Kafka
* CÃ³digo genÃ©rico e extensÃ­vel para novos payloads
* SeparaÃ§Ã£o clara de responsabilidades
* Uso de Docker para padronizaÃ§Ã£o de ambiente
* Testes unitÃ¡rios para garantir estabilidade da soluÃ§Ã£o

---

**Autor:** Gustavo Cunha
**Desafio:** Netshoes